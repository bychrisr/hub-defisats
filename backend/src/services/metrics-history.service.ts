/**
 * Metrics History Service
 * Coleta e armazena m√©tricas hist√≥ricas para an√°lise de tend√™ncias
 */

interface MetricSnapshot {
  timestamp: Date;
  api_latency: number;
  error_rate: number;
  queue_sizes: Record<string, number>;
  ln_markets_status: string;
  system_health: {
    database: string;
    redis: string;
    workers: string;
  };
  memory_usage: number;
  cpu_usage: number;
  active_connections: number;
}

interface MetricAverages {
  api_latency: {
    current: number;
    average_1h: number;
    average_24h: number;
    trend: 'improving' | 'stable' | 'degrading';
    status: 'good' | 'warning' | 'critical';
  };
  error_rate: {
    current: number;
    average_1h: number;
    average_24h: number;
    trend: 'improving' | 'stable' | 'degrading';
    status: 'good' | 'warning' | 'critical';
  };
  memory_usage: {
    current: number;
    average_1h: number;
    average_24h: number;
    trend: 'improving' | 'stable' | 'degrading';
    status: 'good' | 'warning' | 'critical';
  };
  cpu_usage: {
    current: number;
    average_1h: number;
    average_24h: number;
    trend: 'improving' | 'stable' | 'degrading';
    status: 'good' | 'warning' | 'critical';
  };
  queue_health: {
    total_jobs: number;
    average_1h: number;
    average_24h: number;
    trend: 'improving' | 'stable' | 'degrading';
    status: 'good' | 'warning' | 'critical';
  };
}

class MetricsHistoryService {
  private metrics: MetricSnapshot[] = [];
  private readonly MAX_HISTORY_HOURS = 24; // Manter 24 horas de hist√≥rico
  private readonly COLLECTION_INTERVAL = 60000; // Coletar a cada 1 minuto

  constructor() {
    console.log('üöÄ METRICS HISTORY - Service initialized');
    this.startCollection();
  }

  private startCollection() {
    // Coletar m√©tricas a cada minuto
    setInterval(() => {
      this.collectCurrentMetrics();
    }, this.COLLECTION_INTERVAL);

    // Limpar dados antigos a cada hora
    setInterval(() => {
      this.cleanOldMetrics();
    }, 3600000);
  }

  private async collectCurrentMetrics() {
    try {
      console.log('üîç METRICS HISTORY - Collecting metrics...');
      const snapshot: MetricSnapshot = {
        timestamp: new Date(),
        api_latency: this.generateRealisticLatency(),
        error_rate: this.generateRealisticErrorRate(),
        queue_sizes: this.generateRealisticQueueSizes(),
        ln_markets_status: Math.random() > 0.05 ? 'healthy' : 'degraded',
        system_health: {
          database: 'healthy',
          redis: 'healthy',
          workers: 'healthy'
        },
        memory_usage: process.memoryUsage().heapUsed / 1024 / 1024, // MB
        cpu_usage: Math.random() * 100, // Mock CPU usage
        active_connections: Math.floor(Math.random() * 100)
      };

      this.metrics.push(snapshot);
      console.log('‚úÖ METRICS HISTORY - Metrics collected, total:', this.metrics.length);
      
      // Manter apenas as √∫ltimas 24 horas
      const cutoff = new Date(Date.now() - this.MAX_HISTORY_HOURS * 60 * 60 * 1000);
      this.metrics = this.metrics.filter(m => m.timestamp > cutoff);

    } catch (error) {
      console.error('‚ùå Error collecting metrics:', error);
    }
  }

  private generateRealisticLatency(): number {
    // Simular lat√™ncia real√≠stica com varia√ß√µes
    const baseLatency = 80;
    const variation = Math.random() * 40; // ¬±20ms
    const spike = Math.random() < 0.1 ? Math.random() * 200 : 0; // 10% chance de spike
    return Math.floor(baseLatency + variation + spike);
  }

  private generateRealisticErrorRate(): number {
    // Simular taxa de erro real√≠stica
    const baseRate = 0.5;
    const variation = Math.random() * 2;
    const spike = Math.random() < 0.05 ? Math.random() * 5 : 0; // 5% chance de spike
    return Math.round((baseRate + variation + spike) * 100) / 100;
  }

  private generateRealisticQueueSizes(): Record<string, number> {
    const queues = ['automation-execute', 'notification', 'payment-validator', 'email-queue', 'webhook-queue'];
    const sizes: Record<string, number> = {};
    
    queues.forEach(queue => {
      const baseSize = Math.floor(Math.random() * 10);
      const spike = Math.random() < 0.1 ? Math.floor(Math.random() * 20) : 0;
      sizes[queue] = baseSize + spike;
    });

    return sizes;
  }

  private cleanOldMetrics() {
    const cutoff = new Date(Date.now() - this.MAX_HISTORY_HOURS * 60 * 60 * 1000);
    this.metrics = this.metrics.filter(m => m.timestamp > cutoff);
  }

  private calculateAverage(metric: keyof MetricSnapshot, hours: number): number {
    const cutoff = new Date(Date.now() - hours * 60 * 60 * 1000);
    const recentMetrics = this.metrics.filter(m => m.timestamp > cutoff);
    
    if (recentMetrics.length === 0) return 0;

    const sum = recentMetrics.reduce((acc, m) => {
      const value = m[metric];
      if (typeof value === 'number') return acc + value;
      return acc;
    }, 0);

    return Math.round((sum / recentMetrics.length) * 100) / 100;
  }

  private calculateTrend(current: number, average: number): 'improving' | 'stable' | 'degrading' {
    const threshold = 0.1; // 10% de varia√ß√£o
    const change = (current - average) / average;
    
    if (change > threshold) return 'degrading';
    if (change < -threshold) return 'improving';
    return 'stable';
  }

  private getStatus(value: number, thresholds: { good: number; warning: number }): 'good' | 'warning' | 'critical' {
    if (value <= thresholds.good) return 'good';
    if (value <= thresholds.warning) return 'warning';
    return 'critical';
  }

  public getCurrentMetrics(): MetricSnapshot | null {
    console.log('üîç METRICS HISTORY - Current metrics count:', this.metrics.length);
    return this.metrics[this.metrics.length - 1] || null;
  }

  public getMetricsWithAverages(): {
    current: MetricSnapshot;
    averages: MetricAverages;
  } | null {
    const current = this.getCurrentMetrics();
    console.log('üîç METRICS HISTORY - getMetricsWithAverages called, current:', current ? 'Available' : 'Not available');
    if (!current) return null;

    const api_latency_1h = this.calculateAverage('api_latency', 1);
    const api_latency_24h = this.calculateAverage('api_latency', 24);
    const error_rate_1h = this.calculateAverage('error_rate', 1);
    const error_rate_24h = this.calculateAverage('error_rate', 24);
    const memory_1h = this.calculateAverage('memory_usage', 1);
    const memory_24h = this.calculateAverage('memory_usage', 24);
    const cpu_1h = this.calculateAverage('cpu_usage', 1);
    const cpu_24h = this.calculateAverage('cpu_usage', 24);

    // Calcular total de jobs nas filas
    const totalJobs = Object.values(current.queue_sizes).reduce((sum, size) => sum + size, 0);
    const queue_1h = this.calculateQueueAverage(1);
    const queue_24h = this.calculateQueueAverage(24);

    const averages: MetricAverages = {
      api_latency: {
        current: current.api_latency,
        average_1h: api_latency_1h,
        average_24h: api_latency_24h,
        trend: this.calculateTrend(current.api_latency, api_latency_1h),
        status: this.getStatus(current.api_latency, { good: 100, warning: 200 })
      },
      error_rate: {
        current: current.error_rate,
        average_1h: error_rate_1h,
        average_24h: error_rate_24h,
        trend: this.calculateTrend(current.error_rate, error_rate_1h),
        status: this.getStatus(current.error_rate, { good: 1, warning: 3 })
      },
      memory_usage: {
        current: current.memory_usage,
        average_1h: memory_1h,
        average_24h: memory_24h,
        trend: this.calculateTrend(current.memory_usage, memory_1h),
        status: this.getStatus(current.memory_usage, { good: 200, warning: 500 })
      },
      cpu_usage: {
        current: current.cpu_usage,
        average_1h: cpu_1h,
        average_24h: cpu_24h,
        trend: this.calculateTrend(current.cpu_usage, cpu_1h),
        status: this.getStatus(current.cpu_usage, { good: 50, warning: 80 })
      },
      queue_health: {
        total_jobs: totalJobs,
        average_1h: queue_1h,
        average_24h: queue_24h,
        trend: this.calculateTrend(totalJobs, queue_1h),
        status: this.getStatus(totalJobs, { good: 10, warning: 50 })
      }
    };

    return { current, averages };
  }

  private calculateQueueAverage(hours: number): number {
    const cutoff = new Date(Date.now() - hours * 60 * 60 * 1000);
    const recentMetrics = this.metrics.filter(m => m.timestamp > cutoff);
    
    if (recentMetrics.length === 0) return 0;

    const totalJobs = recentMetrics.reduce((acc, m) => {
      return acc + Object.values(m.queue_sizes).reduce((sum, size) => sum + size, 0);
    }, 0);

    return Math.round((totalJobs / recentMetrics.length) * 100) / 100;
  }

  public getHealthSummary(): {
    overall_status: 'healthy' | 'warning' | 'critical';
    issues: string[];
    recommendations: string[];
  } {
    const metricsWithAverages = this.getMetricsWithAverages();
    if (!metricsWithAverages) {
      return {
        overall_status: 'warning',
        issues: ['No metrics data available'],
        recommendations: ['Wait for metrics collection to start']
      };
    }

    const { averages } = metricsWithAverages;
    const issues: string[] = [];
    const recommendations: string[] = [];

    // Verificar API Latency
    if (averages.api_latency.status === 'critical') {
      issues.push(`API latency is critical: ${averages.api_latency.current}ms (avg: ${averages.api_latency.average_24h}ms)`);
      recommendations.push('Check server performance and database queries');
    } else if (averages.api_latency.status === 'warning') {
      issues.push(`API latency is high: ${averages.api_latency.current}ms (avg: ${averages.api_latency.average_24h}ms)`);
      recommendations.push('Monitor server resources and optimize queries');
    }

    // Verificar Error Rate
    if (averages.error_rate.status === 'critical') {
      issues.push(`Error rate is critical: ${averages.error_rate.current}% (avg: ${averages.error_rate.average_24h}%)`);
      recommendations.push('Investigate error logs and fix critical issues');
    } else if (averages.error_rate.status === 'warning') {
      issues.push(`Error rate is elevated: ${averages.error_rate.current}% (avg: ${averages.error_rate.average_24h}%)`);
      recommendations.push('Review recent changes and monitor error patterns');
    }

    // Verificar Memory Usage
    if (averages.memory_usage.status === 'critical') {
      issues.push(`Memory usage is critical: ${averages.memory_usage.current.toFixed(1)}MB (avg: ${averages.memory_usage.average_24h.toFixed(1)}MB)`);
      recommendations.push('Check for memory leaks and consider scaling');
    } else if (averages.memory_usage.status === 'warning') {
      issues.push(`Memory usage is high: ${averages.memory_usage.current.toFixed(1)}MB (avg: ${averages.memory_usage.average_24h.toFixed(1)}MB)`);
      recommendations.push('Monitor memory usage and optimize application');
    }

    // Verificar CPU Usage
    if (averages.cpu_usage.status === 'critical') {
      issues.push(`CPU usage is critical: ${averages.cpu_usage.current.toFixed(1)}% (avg: ${averages.cpu_usage.average_24h.toFixed(1)}%)`);
      recommendations.push('Check for CPU-intensive processes and consider scaling');
    } else if (averages.cpu_usage.status === 'warning') {
      issues.push(`CPU usage is high: ${averages.cpu_usage.current.toFixed(1)}% (avg: ${averages.cpu_usage.average_24h.toFixed(1)}%)`);
      recommendations.push('Monitor CPU usage and optimize performance');
    }

    // Verificar Queue Health
    if (averages.queue_health.status === 'critical') {
      issues.push(`Queue backlog is critical: ${averages.queue_health.total_jobs} jobs (avg: ${averages.queue_health.average_24h})`);
      recommendations.push('Scale workers or investigate queue processing issues');
    } else if (averages.queue_health.status === 'warning') {
      issues.push(`Queue backlog is high: ${averages.queue_health.total_jobs} jobs (avg: ${averages.queue_health.average_24h})`);
      recommendations.push('Monitor queue processing and consider adding workers');
    }

    const overall_status = issues.length === 0 ? 'healthy' : 
                          issues.some(issue => issue.includes('critical')) ? 'critical' : 'warning';

    return {
      overall_status,
      issues,
      recommendations
    };
  }
}

// Export singleton instance
export const metricsHistoryService = new MetricsHistoryService();
export default metricsHistoryService;
